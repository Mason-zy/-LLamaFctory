# Accelerate å­¦ä¹ ä»»åŠ¡æ¸…å•

**æ¨¡å—å‘¨æœŸ**ï¼šDay 5-6ï¼ˆ2 å¤©ï¼‰
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­ï¼ˆä¸­é«˜ï¼‰
**å‰ç½®è¦æ±‚**ï¼šå·²å®Œæˆ Day 3-4 vLLM æ¨¡å—

---

## ğŸ“ æ‰§è¡Œæ—¥å¿—ï¼ˆå®æ—¶æ›´æ–°ï¼‰

### 2026-01-12 | Day 5 æ‰§è¡Œå¼€å§‹

#### âœ… æ­¥éª¤ 0ï¼šå‰ç½®æ£€æŸ¥
```bash
# æ£€æŸ¥å½“å‰ Conda ç¯å¢ƒ
conda activate videofen

# éªŒè¯ PyTorch å’Œ CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}')"

# è®¾ç½®ä½¿ç”¨ GPU 4,5ï¼ˆæœ‰éƒ¨åˆ†å ç”¨ï¼Œå¯å…±äº«ï¼‰
export CUDA_VISIBLE_DEVICES=4,5

# éªŒè¯è®¾ç½®
echo $CUDA_VISIBLE_DEVICES
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**: PyTorch >= 2.0, CUDA >= 12.0, GPU 4,5 å¯ç”¨ï¼ˆå¯å…±äº«ï¼‰
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
```
PyTorch: 2.9.0+cu128
CUDA available: True
GPU count: 2
CUDA_VISIBLE_DEVICES: 4,5
GPU 4,5 æ˜¾å­˜å ç”¨: 76%ï¼ˆä¸å…¶ä»–ä»»åŠ¡å…±äº«ï¼‰
```

**è¯´æ˜**ï¼š
- GPU 4,5 å½“å‰å ç”¨ 76%ï¼Œå‰©ä½™ç©ºé—´è¶³å¤Ÿ Accelerate è®­ç»ƒä»»åŠ¡
- Accelerate è®­ç»ƒæ˜¾å­˜å ç”¨è¿œå°äº vLLM æ¨ç†ï¼ˆè¯¦è§ä¸‹æ–¹å¯¹æ¯”ï¼‰

---

#### âœ… æ­¥éª¤ 1ï¼šå®‰è£… Accelerate
```bash
conda activate videofen
pip install accelerate==0.21.0

# éªŒè¯å®‰è£…
python -c "import accelerate; print(f'Accelerate version: {accelerate.__version__}')"
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**: æ˜¾ç¤º Accelerate ç‰ˆæœ¬å· 0.21.0
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
```
Accelerate version: 0.21.0
```

---

#### âœ… æ­¥éª¤ 2ï¼šé…ç½® Accelerate ç¯å¢ƒ
```bash
# è¿è¡Œé…ç½®å‘å¯¼
accelerate config
```
**äº¤äº’å¼é…ç½®é€‰é¡¹**ï¼š
```
Compute environment: local_machine
Distributed type: MULTI_GPU (DDP)
Number of GPUs: 2
GPU IDs: 4,5
Mixed precision: bf16
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**: ç”Ÿæˆé…ç½®æ–‡ä»¶ `~/.cache/huggingface/accelerate/default_config.yaml`
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
- é…ç½®å‘å¯¼å®Œæˆ
- ä¿®å¤äº†ä¸­æ–‡é€—å·é—®é¢˜ï¼š`gpu_ids: "4,5"`

---

#### âœ… æ­¥éª¤ 2.5ï¼šè¿ç§»é…ç½®æ–‡ä»¶åˆ°é¡¹ç›®ç›®å½•
```bash
# å¤åˆ¶åˆ°æ¨¡å—ç›®å½•
cp /root/.cache/huggingface/accelerate/default_config.yaml /home/zzy/weitiao/modules/04_Accelerate/accelerate_config.yaml

# ä¿®å¤ä¸­æ–‡é€—å·é—®é¢˜ï¼ˆç”¨ nano ç¼–è¾‘æˆ–ç›´æ¥è¦†ç›–ï¼‰
# éªŒè¯é…ç½®
cat /home/zzy/weitiao/modules/04_Accelerate/accelerate_config.yaml
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**å®Œæ•´é…ç½®å†…å®¹**ï¼š
```yaml
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: "4,5"
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
**é…ç½®æ–‡ä»¶ä½ç½®**: `/home/zzy/weitiao/modules/04_Accelerate/accelerate_config.yaml`

---

#### âœ… æ­¥éª¤ 3ï¼šåˆ›å»ºæµ‹è¯•è„šæœ¬
```bash
# åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p /home/zzy/weitiao/experiments/accelerate
cd /home/zzy/weitiao/experiments/accelerate

# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test_accelerate.py << 'EOF'
import torch
from accelerate import Accelerator

print("=" * 60)
print("Accelerate æµ‹è¯•è„šæœ¬")
print("=" * 60)

# åˆå§‹åŒ– Accelerator
accelerator = Accelerator()

# åˆ›å»ºç®€å•æ¨¡å‹
model = torch.nn.Linear(10, 10)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
dataloader = torch.utils.data.DataLoader(
    torch.randn(100, 10), batch_size=10
)

# æ ¸å¿ƒé­”æ³•ï¼šprepare()
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)

# è®­ç»ƒå¾ªç¯
for epoch in range(2):
    for batch in dataloader:
        outputs = model(batch)
        loss = outputs.sum()

        # æ›¿æ¢ loss.backward()
        accelerator.backward(loss)

        optimizer.step()
        optimizer.zero_grad()

    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
    if accelerator.is_main_process:
        print(f"Epoch {epoch} completed")

print(f"\n{'=' * 60}")
print(f"ä½¿ç”¨è®¾å¤‡: {accelerator.device}")
print(f"è¿›ç¨‹ç´¢å¼•: {accelerator.process_index}")
print(f"è¿›ç¨‹æ€»æ•°: {accelerator.num_processes}")
print(f"æ··åˆç²¾åº¦: {accelerator.mixed_precision}")
print(f"æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {accelerator.gradient_accumulation_steps}")
print("=" * 60)
EOF
```
**çŠ¶æ€**: â³ å¾…æ‰§è¡Œ
**å®é™…ç»“æœ**: å¾…è®°å½•

---

#### âœ… æ­¥éª¤ 4ï¼šå•å¡æµ‹è¯•
```bash
cd /home/zzy/weitiao/modules/04_Accelerate
CUDA_VISIBLE_DEVICES=4 python test_accelerate.py
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**:
- ä½¿ç”¨ GPU 4
- è¿›ç¨‹æ€»æ•°: 1
- è®­ç»ƒæ­£å¸¸å®Œæˆ
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
```
Epoch 0 completed
Epoch 1 completed
ä½¿ç”¨è®¾å¤‡: cuda
è¿›ç¨‹ç´¢å¼•: 0
è¿›ç¨‹æ€»æ•°: 1
æ··åˆç²¾åº¦: no (ç›´æ¥è¿è¡Œï¼Œæœªè¯»å–é…ç½®æ–‡ä»¶)
æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: 1
```
**è¯´æ˜**ï¼šç›´æ¥ç”¨ `python` è¿è¡Œä¸ä¼šåº”ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ··åˆç²¾åº¦è®¾ç½®

---

#### âœ… æ­¥éª¤ 5ï¼šåŒå¡æµ‹è¯•
```bash
accelerate launch --config_file accelerate_config.yaml test_accelerate.py
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**:
- ä½¿ç”¨ GPU 4,5
- è¿›ç¨‹æ€»æ•°: 2
- æ··åˆç²¾åº¦ bf16 ç”Ÿæ•ˆ
**å®é™…ç»“æœ**: âœ… æˆåŠŸ
```
è¿›ç¨‹ 0: ä½¿ç”¨è®¾å¤‡ cuda:0 (GPU 4), è¿›ç¨‹ç´¢å¼• 0, æ··åˆç²¾åº¦ bf16
è¿›ç¨‹ 1: ä½¿ç”¨è®¾å¤‡ cuda:1 (GPU 5), è¿›ç¨‹ç´¢å¼• 1, æ··åˆç²¾åº¦ bf16
Epoch 0 completed
Epoch 1 completed
```
**å…³é”®å‘ç°**ï¼š
- âœ… åŒè¿›ç¨‹å¹¶è¡Œè¿è¡Œï¼ˆè¿›ç¨‹ 0 å’Œ 1ï¼‰
- âœ… æ··åˆç²¾åº¦ bf16 ç”Ÿæ•ˆï¼ˆä½¿ç”¨ accelerate launchï¼‰
- âœ… GPU 4â†’cuda:0, GPU 5â†’cuda:1 æ˜ å°„æ­£ç¡®
- âš ï¸ è­¦å‘Šä¿¡æ¯æ­£å¸¸ï¼ˆè¿›ç¨‹ç»„æœªæ˜¾å¼é”€æ¯ï¼Œä¸å½±å“åŠŸèƒ½ï¼‰

---

#### âœ… æ­¥éª¤ 6ï¼šç›‘æ§åŒå¡è®­ç»ƒï¼ˆæ–°ç»ˆç«¯ï¼‰
```bash
nvitop
# æˆ–
watch -n 1 nvidia-smi
```
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**é¢„æœŸ**: GPU 4 å’Œ GPU 5 éƒ½æœ‰æ˜¾å­˜å ç”¨ï¼ˆçº¦ 2-4 GB/å¡ï¼Œä¸å…¶ä»–ä»»åŠ¡å…±äº«ï¼‰
**å®é™…ç»“æœ**: âœ… æ­£å¸¸
```
GPU 4: 18.75 GB (76.4%) - vLLM TP=2 ä»»åŠ¡
GPU 5: 18.75 GB (76.4%) - vLLM TP=2 ä»»åŠ¡
æµ‹è¯•è„šæœ¬è¿è¡Œå: æ˜¾å­˜å ç”¨ä¸å˜ï¼ˆæµ‹è¯•æ¨¡å‹å¤ªå°ï¼Œå¯å¿½ç•¥ï¼‰
```
**è¯´æ˜**ï¼š
- GPU 4-5 å·²æœ‰ vLLM ä»»åŠ¡ï¼ˆ14B æ¨¡å‹å¼ é‡å¹¶è¡Œï¼‰
- Accelerate æµ‹è¯•è„šæœ¬åªæœ‰ 10â†’10 çº¿æ€§å±‚ï¼Œæ˜¾å­˜å ç”¨ < 100 MB
- åŒå¡è®­ç»ƒéªŒè¯æˆåŠŸï¼ˆåŒè¿›ç¨‹å¹¶è¡Œï¼Œæ··åˆç²¾åº¦ bf16ï¼‰

---

### ğŸ“Š Day 5 éªŒæ”¶è¿›åº¦
- [x] Accelerate å®‰è£…æˆåŠŸ âœ…
- [x] é…ç½®æ–‡ä»¶ç”Ÿæˆæ­£ç¡® âœ…
- [x] å•å¡æµ‹è¯•é€šè¿‡ âœ…
- [x] åŒå¡æµ‹è¯•é€šè¿‡ âœ…
- [x] ç†è§£ prepare() æ–¹æ³•ä½œç”¨ âœ…

**Day 5 çŠ¶æ€**: âœ… **å…¨éƒ¨å®Œæˆï¼**

---

## ğŸ‰ Day 5 æ€»ç»“

### âœ… å®Œæˆçš„ä»»åŠ¡
1. âœ… å®‰è£… Accelerate 0.21.0
2. âœ… é…ç½® Accelerate ç¯å¢ƒï¼ˆGPU 4,5 + BF16ï¼‰
3. âœ… åˆ›å»ºé¡¹ç›®çº§é…ç½®æ–‡ä»¶
4. âœ… å•å¡æµ‹è¯•ï¼ˆéªŒè¯åŸºæœ¬åŠŸèƒ½ï¼‰
5. âœ… åŒå¡æµ‹è¯•ï¼ˆéªŒè¯æ•°æ®å¹¶è¡Œï¼‰
6. âœ… æ··åˆç²¾åº¦ BF16 ç”Ÿæ•ˆ

### ğŸ¯ æ ¸å¿ƒæ”¶è·
- **accelerator.prepare()**ï¼šè‡ªåŠ¨å¤„ç†è®¾å¤‡åˆ†é…ã€å¤šå¡åŒæ­¥
- **accelerate launch**ï¼šåº”ç”¨é…ç½®æ–‡ä»¶çš„å”¯ä¸€æ–¹å¼
- **is_main_process**ï¼šé¿å…å¤šè¿›ç¨‹é‡å¤è¾“å‡º
- **bf16 vs no**ï¼šé…ç½®æ–‡ä»¶ä¸­çš„æ··åˆç²¾åº¦åªåœ¨ `accelerate launch` æ—¶ç”Ÿæ•ˆ

### ğŸ“ å…³é”®å‘½ä»¤
```bash
# é…ç½®å‘å¯¼
accelerate config

# å•å¡è¿è¡Œï¼ˆä¸åº”ç”¨é…ç½®æ–‡ä»¶ï¼‰
CUDA_VISIBLE_DEVICES=4 python test_accelerate.py

# åŒå¡è¿è¡Œï¼ˆåº”ç”¨é…ç½®æ–‡ä»¶ï¼‰
accelerate launch --config_file accelerate_config.yaml test_accelerate.py
```

---

---

## ğŸ“‹ å­¦ä¹ ç›®æ ‡

- [ ] ç†è§£ Accelerate çš„æ ¸å¿ƒä»·å€¼ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒæŠ½è±¡å±‚ï¼‰
- [ ] æŒæ¡ Accelerator API çš„ä½¿ç”¨
- [ ] æŒæ¡é…ç½®æ–‡ä»¶ä¸å¯åŠ¨å™¨ï¼ˆaccelerate config/launchï¼‰
- [ ] åŒå¡æ•°æ®å¹¶è¡Œè®­ç»ƒå®è·µ
- [ ] æ··åˆç²¾åº¦è®­ç»ƒï¼ˆBF16ï¼‰

---

## ğŸ“… Day 5ï¼šç¯å¢ƒé…ç½®ä¸æ ¸å¿ƒ API

### ä»»åŠ¡æ¸…å•

#### ä¸Šåˆï¼šç†è®ºç†è§£ï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] é˜…è¯» `modules/04_Accelerate/readme.md`
  - [ ] ç†è§£ Accelerate åœ¨å·¥å…·é“¾ä¸­çš„ä½ç½®
  - [ ] ç†è§£ä¸ºä»€ä¹ˆéœ€è¦ Accelerateï¼ˆä»£ç å¤ç”¨ï¼‰
  - [ ] ç†è§£ Accelerator å¯¹è±¡çš„èŒè´£
  - [ ] ç†è§£ `prepare()` æ–¹æ³•çš„é­”æ³•

- [ ] å®Œæˆç†è®ºè‡ªæµ‹é¢˜
  ```
  Q1: Accelerate è§£å†³äº†ä»€ä¹ˆç—›ç‚¹ï¼Ÿ
  Q2: Accelerate å’Œ DeepSpeed æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
  Q3: prepare() æ–¹æ³•ä¸ºä»€ä¹ˆä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡ï¼Ÿ
  ```

#### ä¸‹åˆï¼šç¯å¢ƒé…ç½®ï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] å®‰è£…/å‡çº§ Accelerate
  ```bash
  conda activate videofen
  pip install accelerate==0.21.0

  # éªŒè¯å®‰è£…
  python -c "import accelerate; print(accelerate.__version__)"
  ```

- [ ] è¿è¡Œé…ç½®å‘å¯¼
  ```bash
  accelerate config
  ```

  **äº¤äº’å¼é…ç½®é€‰é¡¹**ï¼š
  ```
  Compute environment: local_machine
  Distributed type: MULTI_GPU (DDP)
  Number of GPUs: 2
  Mixed precision: bf16
  ```

- [ ] æŸ¥çœ‹ç”Ÿæˆçš„é…ç½®æ–‡ä»¶
  ```bash
  cat ~/.cache/huggingface/accelerate/default_config.yaml
  ```

  **å…³é”®é…ç½®é¡¹**ï¼š
  ```yaml
  compute_environment: LOCAL_MACHINE
  distributed_type: MULTI_GPU
  num_processes: 2
  mixed_precision: bf16
  ```

#### æ™šä¸Šï¼šæ ¸å¿ƒ API å®è·µï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_accelerate.py`
  ```python
  import torch
  from accelerate import Accelerator

  # åˆå§‹åŒ– Accelerator
  accelerator = Accelerator()

  # åˆ›å»ºç®€å•æ¨¡å‹
  model = torch.nn.Linear(10, 10)
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
  dataloader = torch.utils.data.DataLoader(
      torch.randn(100, 10), batch_size=10
  )

  # æ ¸å¿ƒé­”æ³•ï¼šprepare()
  model, optimizer, dataloader = accelerator.prepare(
      model, optimizer, dataloader
  )

  # è®­ç»ƒå¾ªç¯
  for epoch in range(2):
      for batch in dataloader:
          outputs = model(batch)
          loss = outputs.sum()

          # æ›¿æ¢ loss.backward()
          accelerator.backward(loss)

          optimizer.step()
          optimizer.zero_grad()

      # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
      if accelerator.is_main_process:
          print(f"Epoch {epoch} completed")

  print(f"Using device: {accelerator.device}")
  print(f"Process index: {accelerator.process_index}")
  print(f"Num processes: {accelerator.num_processes}")
  ```

- [ ] å•å¡æµ‹è¯•
  ```bash
  CUDA_VISIBLE_DEVICES=0 python test_accelerate.py
  ```

- [ ] åŒå¡æµ‹è¯•
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch test_accelerate.py
  ```

**Day 5 éªŒæ”¶æ ‡å‡†**ï¼š
- [ ] æˆåŠŸé…ç½® Accelerate
- [ ] ç†è§£é…ç½®æ–‡ä»¶çš„ç»“æ„
- [ ] å•å¡/åŒå¡æµ‹è¯•è„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] ç†è§£ `prepare()` å’Œ `backward()` çš„ä½œç”¨

---

## ğŸ“… Day 6ï¼šåŒå¡è®­ç»ƒä¸æ··åˆç²¾åº¦

### ä»»åŠ¡æ¸…å•

#### ä¸Šåˆï¼šæ•°æ®å¹¶è¡Œè®­ç»ƒï¼ˆ3-4 å°æ—¶ï¼‰
- [ ] ç†è§£æ•°æ®å¹¶è¡ŒåŸç†
  - [ ] æ¯å¼ å¡å¤„ç†ä¸åŒçš„ batch
  - [ ] æ¢¯åº¦è‡ªåŠ¨åŒæ­¥
  - [ ] ä¸ºä»€ä¹ˆèƒ½çº¿æ€§åŠ é€Ÿ

- [ ] åˆ›å»ºçœŸå®è®­ç»ƒè„šæœ¬ `train_simple.py`
  ```python
  import torch
  import torch.nn.functional as F
  from accelerate import Accelerator
  from torch.utils.data import DataLoader, TensorDataset

  # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
  X = torch.randn(1000, 10)
  y = torch.randint(0, 2, (1000,))
  dataset = TensorDataset(X, y)
  dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

  # åˆå§‹åŒ–
  accelerator = Accelerator()
  model = torch.nn.Sequential(
      torch.nn.Linear(10, 64),
      torch.nn.ReLU(),
      torch.nn.Linear(64, 2)
  )
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

  # Prepare
  model, optimizer, dataloader = accelerator.prepare(
      model, optimizer, dataloader
  )

  # è®­ç»ƒ
  model.train()
  for epoch in range(5):
      total_loss = 0
      for X_batch, y_batch in dataloader:
          outputs = model(X_batch)
          loss = F.cross_entropy(outputs, y_batch)

          accelerator.backward(loss)
          optimizer.step()
          optimizer.zero_grad()

          total_loss += loss.detach()

      # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
      if accelerator.is_main_process:
          avg_loss = total_loss.item() / len(dataloader)
          print(f"Epoch {epoch}, Loss: {avg_loss:.4f}")
  ```

- [ ] å•å¡è®­ç»ƒï¼ˆåŸºå‡†ï¼‰
  ```bash
  CUDA_VISIBLE_DEVICES=0 python train_simple.py
  ```

- [ ] åŒå¡è®­ç»ƒ
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch train_simple.py
  ```

- [ ] è®°å½•è®­ç»ƒæ—¶é—´å¯¹æ¯”
  | é…ç½® | è®­ç»ƒæ—¶é—´ | åŠ é€Ÿæ¯” |
  |------|----------|--------|
  | å•å¡ | ? ç§’ | 1.0Ã— |
  | åŒå¡ | ? ç§’ | ?Ã— |

#### ä¸‹åˆï¼šæ··åˆç²¾åº¦è®­ç»ƒï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] ç†è§£æ··åˆç²¾åº¦åŸç†
  - [ ] FP16/BF16 vs FP32
  - [ ] æ˜¾å­˜èŠ‚çœï¼ˆçº¦ 50%ï¼‰
  - [ ] é€Ÿåº¦æå‡ï¼ˆçº¦ 2-3Ã—ï¼‰

- [ ] ä¿®æ”¹é…ç½®å¼€å¯ BF16
  ```bash
  accelerate config
  # é€‰æ‹© mixed_precision: bf16
  ```

- [ ] æˆ–ç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶
  ```yaml
  # ~/.cache/huggingface/accelerate/default_config.yaml
  mixed_precision: bf16
  ```

- [ ] è¿è¡Œæ··åˆç²¾åº¦è®­ç»ƒ
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch train_simple.py
  ```

- [ ] å¯¹æ¯” FP32 vs BF16
  | ç²¾åº¦ | è®­ç»ƒæ—¶é—´ | æ˜¾å­˜å ç”¨ | é€Ÿåº¦æå‡ |
  |------|----------|----------|----------|
  | FP32 | ? ç§’ | ? GB | 1.0Ã— |
  | BF16 | ? ç§’ | ? GB | ?Ã— |

#### æ™šä¸Šï¼šæ¢¯åº¦ç´¯ç§¯å®éªŒï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] ç†è§£æ¢¯åº¦ç´¯ç§¯åŸç†
  - [ ] å°æ˜¾å­˜æ¨¡æ‹Ÿå¤§ batch
  - [ ] å¤šæ¬¡è®¡ç®—ã€ä¸€æ¬¡æ›´æ–°

- [ ] ä¿®æ”¹è®­ç»ƒè„šæœ¬æ·»åŠ æ¢¯åº¦ç´¯ç§¯
  ```python
  # åœ¨ train_simple.py ä¸­æ·»åŠ 
  gradient_accumulation_steps = 4

  for epoch in range(5):
      for i, (X_batch, y_batch) in enumerate(dataloader):
          with accelerator.accumulate(model):
              outputs = model(X_batch)
              loss = F.cross_entropy(outputs, y_batch)

              accelerator.backward(loss)
              optimizer.step()
              optimizer.zero_grad()
  ```

- [ ] å¯¹æ¯”ä¸åŒç´¯ç§¯æ­¥æ•°
  | ç´¯ç§¯æ­¥æ•° | æœ‰æ•ˆ Batch Size | è®­ç»ƒæ—¶é—´ |
  |----------|----------------|----------|
  | 1 | 32 | ? ç§’ |
  | 4 | 128 | ? ç§’ |
  | 8 | 256 | ? ç§’ |

**Day 6 éªŒæ”¶æ ‡å‡†**ï¼š
- [ ] åŒå¡æ•°æ®å¹¶è¡Œè®­ç»ƒæˆåŠŸ
- [ ] åŠ é€Ÿæ¯” > 1.8Ã—
- [ ] æ··åˆç²¾åº¦è®­ç»ƒæˆåŠŸï¼ˆé€Ÿåº¦æå‡ > 2Ã—ï¼‰
- [ ] ç†è§£æ¢¯åº¦ç´¯ç§¯çš„ä½œç”¨

---

## ğŸ¯ æ¨¡å—éªŒæ”¶æ ‡å‡†

### ç†è®ºéªŒæ”¶
- [ ] èƒ½è§£é‡Š Accelerate çš„æ ¸å¿ƒä»·å€¼
- [ ] èƒ½è¯´æ˜æ•°æ®å¹¶è¡Œçš„åŸç†
- [ ] èƒ½è§£é‡Šæ··åˆç²¾åº¦çš„ä¼˜åŠ¿
- [ ] èƒ½è¯´æ˜æ¢¯åº¦ç´¯ç§¯çš„åº”ç”¨åœºæ™¯

### å®æ“éªŒæ”¶
- [ ] æˆåŠŸé…ç½® Accelerateï¼ˆå•å¡/åŒå¡ï¼‰
- [ ] åŒå¡è®­ç»ƒåŠ é€Ÿæ¯” > 1.8Ã—
- [ ] æ··åˆç²¾åº¦è®­ç»ƒé€Ÿåº¦æå‡ > 2Ã—
- [ ] èƒ½ä½¿ç”¨ `accelerator.gather()` æ±‡æ€»æ•°æ®

### è¾“å‡ºç‰©
- [ ] è®­ç»ƒæ€§èƒ½å¯¹æ¯”è¡¨ï¼ˆå•å¡ vs åŒå¡ vs BF16ï¼‰
- [ ] é…ç½®æ–‡ä»¶ç¬”è®°ï¼ˆå«å…³é”®å‚æ•°è¯´æ˜ï¼‰
- [ ] æ¢¯åº¦ç´¯ç§¯å®éªŒæ•°æ®

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Accelerate GitHub](https://github.com/huggingface/accelerate)
- [Accelerate å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/accelerate/)
- [åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å—](https://huggingface.co/docs/accelerate/usage_guides/distributed_training)

### æ¨èé˜…è¯»
- `modules/04_Accelerate/readme.md`ï¼ˆå®Œæ•´ç†è®ºæŒ‡å—ï¼‰

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥
```bash
# é…ç½®å‘å¯¼
accelerate config

# å¯åŠ¨è®­ç»ƒ
accelerate launch train.py

# æŸ¥çœ‹é…ç½®
cat ~/.cache/huggingface/accelerate/default_config.yaml

# æµ‹è¯•ç¯å¢ƒ
accelerate env
```

### æ ¸å¿ƒä»£ç æ¨¡æ¿
```python
from accelerate import Accelerator

# åˆå§‹åŒ–
accelerator = Accelerator(
    mixed_precision="bf16",  # fp16/bf16/no
    gradient_accumulation_steps=4
)

# Prepare
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)

# è®­ç»ƒå¾ªç¯
for batch in dataloader:
    with accelerator.accumulate(model):
        loss = model(batch)
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()

# åªåœ¨ä¸»è¿›ç¨‹æ‰§è¡Œ
if accelerator.is_main_process:
    print("Result")

# æ±‡æ€»å¤šå¡æ•°æ®
all_results = accelerator.gather(results)
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: accelerate launch æŠ¥é”™ "CUDA not available"ï¼Ÿ
**A**: æ£€æŸ¥ `CUDA_VISIBLE_DEVICES` è®¾ç½®
```bash
# æ£€æŸ¥ GPU å¯è§æ€§
python -c "import torch; print(torch.cuda.device_count())"

# ç¡®ä¿è®¾ç½®äº†æ­£ç¡®çš„ GPU
export CUDA_VISIBLE_DEVICES=0,1
```

### Q2: åŒå¡è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡ï¼Ÿ
**A**: æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦ç“¶é¢ˆ
```python
# å¢åŠ  dataloader workers
dataloader = DataLoader(dataset, batch_size=32, num_workers=4)
```

### Q3: æ··åˆç²¾åº¦è®­ç»ƒå‡ºç° NaNï¼Ÿ
**A**: é™ä½å­¦ä¹ ç‡æˆ–ä½¿ç”¨æ¢¯åº¦ç¼©æ”¾
```python
accelerator = Accelerator(mixed_precision="bf16")
# æˆ–é™ä½å­¦ä¹ ç‡
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
```

---

## ğŸ”„ ä¸åç»­æ¨¡å—çš„è¡”æ¥

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ å°†æŒæ¡ï¼š
- âœ… åˆ†å¸ƒå¼è®­ç»ƒçš„ç»Ÿä¸€æŠ½è±¡
- âœ… æ•°æ®å¹¶è¡Œä¸æ··åˆç²¾åº¦
- âœ… æ¢¯åº¦ç´¯ç§¯æŠ€æœ¯

**ä¸‹ä¸€æ¨¡å—**ï¼šDay 7-8 DeepSpeed æ˜¾å­˜ä¼˜åŒ–
- å­¦ä¹  ZeRO ä¸‰é˜¶æ®µä¼˜åŒ–
- è§£å†³æ˜¾å­˜ä¸è¶³é—®é¢˜
- ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰“åŸºç¡€
