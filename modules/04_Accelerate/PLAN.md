# Accelerate å­¦ä¹ ä»»åŠ¡æ¸…å•

**æ¨¡å—å‘¨æœŸ**ï¼šDay 5-6ï¼ˆ2 å¤©ï¼‰
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­ï¼ˆä¸­é«˜ï¼‰
**å‰ç½®è¦æ±‚**ï¼šå·²å®Œæˆ Day 3-4 vLLM æ¨¡å—

---

## ğŸ“‹ å­¦ä¹ ç›®æ ‡

- [ ] ç†è§£ Accelerate çš„æ ¸å¿ƒä»·å€¼ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒæŠ½è±¡å±‚ï¼‰
- [ ] æŒæ¡ Accelerator API çš„ä½¿ç”¨
- [ ] æŒæ¡é…ç½®æ–‡ä»¶ä¸å¯åŠ¨å™¨ï¼ˆaccelerate config/launchï¼‰
- [ ] åŒå¡æ•°æ®å¹¶è¡Œè®­ç»ƒå®è·µ
- [ ] æ··åˆç²¾åº¦è®­ç»ƒï¼ˆBF16ï¼‰

---

## ğŸ“… Day 5ï¼šç¯å¢ƒé…ç½®ä¸æ ¸å¿ƒ API

### ä»»åŠ¡æ¸…å•

#### ä¸Šåˆï¼šç†è®ºç†è§£ï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] é˜…è¯» `modules/04_Accelerate/readme.md`
  - [ ] ç†è§£ Accelerate åœ¨å·¥å…·é“¾ä¸­çš„ä½ç½®
  - [ ] ç†è§£ä¸ºä»€ä¹ˆéœ€è¦ Accelerateï¼ˆä»£ç å¤ç”¨ï¼‰
  - [ ] ç†è§£ Accelerator å¯¹è±¡çš„èŒè´£
  - [ ] ç†è§£ `prepare()` æ–¹æ³•çš„é­”æ³•

- [ ] å®Œæˆç†è®ºè‡ªæµ‹é¢˜
  ```
  Q1: Accelerate è§£å†³äº†ä»€ä¹ˆç—›ç‚¹ï¼Ÿ
  Q2: Accelerate å’Œ DeepSpeed æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
  Q3: prepare() æ–¹æ³•ä¸ºä»€ä¹ˆä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡ï¼Ÿ
  ```

#### ä¸‹åˆï¼šç¯å¢ƒé…ç½®ï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] å®‰è£…/å‡çº§ Accelerate
  ```bash
  conda activate videofen
  pip install accelerate==0.21.0

  # éªŒè¯å®‰è£…
  python -c "import accelerate; print(accelerate.__version__)"
  ```

- [ ] è¿è¡Œé…ç½®å‘å¯¼
  ```bash
  accelerate config
  ```

  **äº¤äº’å¼é…ç½®é€‰é¡¹**ï¼š
  ```
  Compute environment: local_machine
  Distributed type: MULTI_GPU (DDP)
  Number of GPUs: 2
  Mixed precision: bf16
  ```

- [ ] æŸ¥çœ‹ç”Ÿæˆçš„é…ç½®æ–‡ä»¶
  ```bash
  cat ~/.cache/huggingface/accelerate/default_config.yaml
  ```

  **å…³é”®é…ç½®é¡¹**ï¼š
  ```yaml
  compute_environment: LOCAL_MACHINE
  distributed_type: MULTI_GPU
  num_processes: 2
  mixed_precision: bf16
  ```

#### æ™šä¸Šï¼šæ ¸å¿ƒ API å®è·µï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_accelerate.py`
  ```python
  import torch
  from accelerate import Accelerator

  # åˆå§‹åŒ– Accelerator
  accelerator = Accelerator()

  # åˆ›å»ºç®€å•æ¨¡å‹
  model = torch.nn.Linear(10, 10)
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
  dataloader = torch.utils.data.DataLoader(
      torch.randn(100, 10), batch_size=10
  )

  # æ ¸å¿ƒé­”æ³•ï¼šprepare()
  model, optimizer, dataloader = accelerator.prepare(
      model, optimizer, dataloader
  )

  # è®­ç»ƒå¾ªç¯
  for epoch in range(2):
      for batch in dataloader:
          outputs = model(batch)
          loss = outputs.sum()

          # æ›¿æ¢ loss.backward()
          accelerator.backward(loss)

          optimizer.step()
          optimizer.zero_grad()

      # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
      if accelerator.is_main_process:
          print(f"Epoch {epoch} completed")

  print(f"Using device: {accelerator.device}")
  print(f"Process index: {accelerator.process_index}")
  print(f"Num processes: {accelerator.num_processes}")
  ```

- [ ] å•å¡æµ‹è¯•
  ```bash
  CUDA_VISIBLE_DEVICES=0 python test_accelerate.py
  ```

- [ ] åŒå¡æµ‹è¯•
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch test_accelerate.py
  ```

**Day 5 éªŒæ”¶æ ‡å‡†**ï¼š
- [ ] æˆåŠŸé…ç½® Accelerate
- [ ] ç†è§£é…ç½®æ–‡ä»¶çš„ç»“æ„
- [ ] å•å¡/åŒå¡æµ‹è¯•è„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] ç†è§£ `prepare()` å’Œ `backward()` çš„ä½œç”¨

---

## ğŸ“… Day 6ï¼šåŒå¡è®­ç»ƒä¸æ··åˆç²¾åº¦

### ä»»åŠ¡æ¸…å•

#### ä¸Šåˆï¼šæ•°æ®å¹¶è¡Œè®­ç»ƒï¼ˆ3-4 å°æ—¶ï¼‰
- [ ] ç†è§£æ•°æ®å¹¶è¡ŒåŸç†
  - [ ] æ¯å¼ å¡å¤„ç†ä¸åŒçš„ batch
  - [ ] æ¢¯åº¦è‡ªåŠ¨åŒæ­¥
  - [ ] ä¸ºä»€ä¹ˆèƒ½çº¿æ€§åŠ é€Ÿ

- [ ] åˆ›å»ºçœŸå®è®­ç»ƒè„šæœ¬ `train_simple.py`
  ```python
  import torch
  import torch.nn.functional as F
  from accelerate import Accelerator
  from torch.utils.data import DataLoader, TensorDataset

  # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
  X = torch.randn(1000, 10)
  y = torch.randint(0, 2, (1000,))
  dataset = TensorDataset(X, y)
  dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

  # åˆå§‹åŒ–
  accelerator = Accelerator()
  model = torch.nn.Sequential(
      torch.nn.Linear(10, 64),
      torch.nn.ReLU(),
      torch.nn.Linear(64, 2)
  )
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

  # Prepare
  model, optimizer, dataloader = accelerator.prepare(
      model, optimizer, dataloader
  )

  # è®­ç»ƒ
  model.train()
  for epoch in range(5):
      total_loss = 0
      for X_batch, y_batch in dataloader:
          outputs = model(X_batch)
          loss = F.cross_entropy(outputs, y_batch)

          accelerator.backward(loss)
          optimizer.step()
          optimizer.zero_grad()

          total_loss += loss.detach()

      # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
      if accelerator.is_main_process:
          avg_loss = total_loss.item() / len(dataloader)
          print(f"Epoch {epoch}, Loss: {avg_loss:.4f}")
  ```

- [ ] å•å¡è®­ç»ƒï¼ˆåŸºå‡†ï¼‰
  ```bash
  CUDA_VISIBLE_DEVICES=0 python train_simple.py
  ```

- [ ] åŒå¡è®­ç»ƒ
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch train_simple.py
  ```

- [ ] è®°å½•è®­ç»ƒæ—¶é—´å¯¹æ¯”
  | é…ç½® | è®­ç»ƒæ—¶é—´ | åŠ é€Ÿæ¯” |
  |------|----------|--------|
  | å•å¡ | ? ç§’ | 1.0Ã— |
  | åŒå¡ | ? ç§’ | ?Ã— |

#### ä¸‹åˆï¼šæ··åˆç²¾åº¦è®­ç»ƒï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] ç†è§£æ··åˆç²¾åº¦åŸç†
  - [ ] FP16/BF16 vs FP32
  - [ ] æ˜¾å­˜èŠ‚çœï¼ˆçº¦ 50%ï¼‰
  - [ ] é€Ÿåº¦æå‡ï¼ˆçº¦ 2-3Ã—ï¼‰

- [ ] ä¿®æ”¹é…ç½®å¼€å¯ BF16
  ```bash
  accelerate config
  # é€‰æ‹© mixed_precision: bf16
  ```

- [ ] æˆ–ç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶
  ```yaml
  # ~/.cache/huggingface/accelerate/default_config.yaml
  mixed_precision: bf16
  ```

- [ ] è¿è¡Œæ··åˆç²¾åº¦è®­ç»ƒ
  ```bash
  CUDA_VISIBLE_DEVICES=0,1 accelerate launch train_simple.py
  ```

- [ ] å¯¹æ¯” FP32 vs BF16
  | ç²¾åº¦ | è®­ç»ƒæ—¶é—´ | æ˜¾å­˜å ç”¨ | é€Ÿåº¦æå‡ |
  |------|----------|----------|----------|
  | FP32 | ? ç§’ | ? GB | 1.0Ã— |
  | BF16 | ? ç§’ | ? GB | ?Ã— |

#### æ™šä¸Šï¼šæ¢¯åº¦ç´¯ç§¯å®éªŒï¼ˆ2-3 å°æ—¶ï¼‰
- [ ] ç†è§£æ¢¯åº¦ç´¯ç§¯åŸç†
  - [ ] å°æ˜¾å­˜æ¨¡æ‹Ÿå¤§ batch
  - [ ] å¤šæ¬¡è®¡ç®—ã€ä¸€æ¬¡æ›´æ–°

- [ ] ä¿®æ”¹è®­ç»ƒè„šæœ¬æ·»åŠ æ¢¯åº¦ç´¯ç§¯
  ```python
  # åœ¨ train_simple.py ä¸­æ·»åŠ 
  gradient_accumulation_steps = 4

  for epoch in range(5):
      for i, (X_batch, y_batch) in enumerate(dataloader):
          with accelerator.accumulate(model):
              outputs = model(X_batch)
              loss = F.cross_entropy(outputs, y_batch)

              accelerator.backward(loss)
              optimizer.step()
              optimizer.zero_grad()
  ```

- [ ] å¯¹æ¯”ä¸åŒç´¯ç§¯æ­¥æ•°
  | ç´¯ç§¯æ­¥æ•° | æœ‰æ•ˆ Batch Size | è®­ç»ƒæ—¶é—´ |
  |----------|----------------|----------|
  | 1 | 32 | ? ç§’ |
  | 4 | 128 | ? ç§’ |
  | 8 | 256 | ? ç§’ |

**Day 6 éªŒæ”¶æ ‡å‡†**ï¼š
- [ ] åŒå¡æ•°æ®å¹¶è¡Œè®­ç»ƒæˆåŠŸ
- [ ] åŠ é€Ÿæ¯” > 1.8Ã—
- [ ] æ··åˆç²¾åº¦è®­ç»ƒæˆåŠŸï¼ˆé€Ÿåº¦æå‡ > 2Ã—ï¼‰
- [ ] ç†è§£æ¢¯åº¦ç´¯ç§¯çš„ä½œç”¨

---

## ğŸ¯ æ¨¡å—éªŒæ”¶æ ‡å‡†

### ç†è®ºéªŒæ”¶
- [ ] èƒ½è§£é‡Š Accelerate çš„æ ¸å¿ƒä»·å€¼
- [ ] èƒ½è¯´æ˜æ•°æ®å¹¶è¡Œçš„åŸç†
- [ ] èƒ½è§£é‡Šæ··åˆç²¾åº¦çš„ä¼˜åŠ¿
- [ ] èƒ½è¯´æ˜æ¢¯åº¦ç´¯ç§¯çš„åº”ç”¨åœºæ™¯

### å®æ“éªŒæ”¶
- [ ] æˆåŠŸé…ç½® Accelerateï¼ˆå•å¡/åŒå¡ï¼‰
- [ ] åŒå¡è®­ç»ƒåŠ é€Ÿæ¯” > 1.8Ã—
- [ ] æ··åˆç²¾åº¦è®­ç»ƒé€Ÿåº¦æå‡ > 2Ã—
- [ ] èƒ½ä½¿ç”¨ `accelerator.gather()` æ±‡æ€»æ•°æ®

### è¾“å‡ºç‰©
- [ ] è®­ç»ƒæ€§èƒ½å¯¹æ¯”è¡¨ï¼ˆå•å¡ vs åŒå¡ vs BF16ï¼‰
- [ ] é…ç½®æ–‡ä»¶ç¬”è®°ï¼ˆå«å…³é”®å‚æ•°è¯´æ˜ï¼‰
- [ ] æ¢¯åº¦ç´¯ç§¯å®éªŒæ•°æ®

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Accelerate GitHub](https://github.com/huggingface/accelerate)
- [Accelerate å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/accelerate/)
- [åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å—](https://huggingface.co/docs/accelerate/usage_guides/distributed_training)

### æ¨èé˜…è¯»
- `modules/04_Accelerate/readme.md`ï¼ˆå®Œæ•´ç†è®ºæŒ‡å—ï¼‰

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥
```bash
# é…ç½®å‘å¯¼
accelerate config

# å¯åŠ¨è®­ç»ƒ
accelerate launch train.py

# æŸ¥çœ‹é…ç½®
cat ~/.cache/huggingface/accelerate/default_config.yaml

# æµ‹è¯•ç¯å¢ƒ
accelerate env
```

### æ ¸å¿ƒä»£ç æ¨¡æ¿
```python
from accelerate import Accelerator

# åˆå§‹åŒ–
accelerator = Accelerator(
    mixed_precision="bf16",  # fp16/bf16/no
    gradient_accumulation_steps=4
)

# Prepare
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)

# è®­ç»ƒå¾ªç¯
for batch in dataloader:
    with accelerator.accumulate(model):
        loss = model(batch)
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()

# åªåœ¨ä¸»è¿›ç¨‹æ‰§è¡Œ
if accelerator.is_main_process:
    print("Result")

# æ±‡æ€»å¤šå¡æ•°æ®
all_results = accelerator.gather(results)
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: accelerate launch æŠ¥é”™ "CUDA not available"ï¼Ÿ
**A**: æ£€æŸ¥ `CUDA_VISIBLE_DEVICES` è®¾ç½®
```bash
# æ£€æŸ¥ GPU å¯è§æ€§
python -c "import torch; print(torch.cuda.device_count())"

# ç¡®ä¿è®¾ç½®äº†æ­£ç¡®çš„ GPU
export CUDA_VISIBLE_DEVICES=0,1
```

### Q2: åŒå¡è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡ï¼Ÿ
**A**: æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦ç“¶é¢ˆ
```python
# å¢åŠ  dataloader workers
dataloader = DataLoader(dataset, batch_size=32, num_workers=4)
```

### Q3: æ··åˆç²¾åº¦è®­ç»ƒå‡ºç° NaNï¼Ÿ
**A**: é™ä½å­¦ä¹ ç‡æˆ–ä½¿ç”¨æ¢¯åº¦ç¼©æ”¾
```python
accelerator = Accelerator(mixed_precision="bf16")
# æˆ–é™ä½å­¦ä¹ ç‡
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
```

---

## ğŸ”„ ä¸åç»­æ¨¡å—çš„è¡”æ¥

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ å°†æŒæ¡ï¼š
- âœ… åˆ†å¸ƒå¼è®­ç»ƒçš„ç»Ÿä¸€æŠ½è±¡
- âœ… æ•°æ®å¹¶è¡Œä¸æ··åˆç²¾åº¦
- âœ… æ¢¯åº¦ç´¯ç§¯æŠ€æœ¯

**ä¸‹ä¸€æ¨¡å—**ï¼šDay 7-8 DeepSpeed æ˜¾å­˜ä¼˜åŒ–
- å­¦ä¹  ZeRO ä¸‰é˜¶æ®µä¼˜åŒ–
- è§£å†³æ˜¾å­˜ä¸è¶³é—®é¢˜
- ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰“åŸºç¡€
