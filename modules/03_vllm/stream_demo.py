# -*- coding: utf-8 -*-
"""
vLLM æµå¼è¾“å‡ºç¤ºä¾‹
ä½œè€…: zhouzhiyong
è¯´æ˜: æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ vLLM çš„æµå¼ API è¿›è¡Œå®æ—¶å¯¹è¯
"""

import requests
import json


def stream_chat(prompt, model_path="/home/zzy/weitiao/models/Qwen2.5-7B-Instruct",
                base_url="http://36.155.142.146:8000", temperature=0.7):
    """
    æµå¼å¯¹è¯å‡½æ•°

    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        model_path: æ¨¡å‹è·¯å¾„
        base_url: vLLM æœåŠ¡åœ°å€ï¼ˆå±€åŸŸç½‘ IPï¼‰
        temperature: æ¸©åº¦å‚æ•°ï¼ˆ0.0-1.0ï¼‰

    Returns:
        å®Œæ•´å›å¤æ–‡æœ¬
    """
    url = f"{base_url}/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model_path,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "stream": True  # å…³é”®å‚æ•°ï¼šå¯ç”¨æµå¼è¾“å‡º
    }

    print(f"ğŸ¤– Prompt: {prompt}")
    print(f"ğŸ“¡ Connecting to {base_url}...")
    print("ğŸ’¬ Assistant: ", end="", flush=True)

    full_response = ""

    try:
        # å‘é€ POST è¯·æ±‚ï¼Œå¯ç”¨æµå¼ä¼ è¾“
        response = requests.post(url, headers=headers, json=data, stream=True)
        response.raise_for_status()

        # é€è¡Œè¯»å– SSE (Server-Sent Events) æ ¼å¼
        for line in response.iter_lines():
            if not line:
                continue

            line = line.decode('utf-8')

            # SSE æ ¼å¼ï¼šdata: {...}
            if line.startswith('data: '):
                data_str = line[6:]  # å»æ‰ 'data: ' å‰ç¼€

                # ç»“æŸæ ‡å¿—
                if data_str == '[DONE]':
                    break

                try:
                    # è§£æ JSON æ•°æ®
                    chunk = json.loads(data_str)
                    delta = chunk['choices'][0].get('delta', {})
                    content = delta.get('content', '')

                    if content:
                        print(content, end="", flush=True)  # å®æ—¶è¾“å‡º
                        full_response += content

                except json.JSONDecodeError:
                    continue

        print()  # æ¢è¡Œ
        return full_response

    except requests.exceptions.RequestException as e:
        print(f"\nâŒ è¯·æ±‚é”™è¯¯: {e}")
        return None


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºä¸åŒçš„å¯¹è¯åœºæ™¯"""
    print("=" * 60)
    print("vLLM æµå¼è¾“å‡ºæ¼”ç¤º")
    print("=" * 60)
    print()

    # æµ‹è¯•åœºæ™¯
    test_prompts = [
        "ç”¨ä¸‰ä¸ªè¯æè¿°æ·±åº¦å­¦ä¹ ",
        "ä»€ä¹ˆæ˜¯ Transformer æ¨¡å‹ï¼Ÿ",
        "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—"
    ]

    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nã€æµ‹è¯• {i}/{len(test_prompts)}ã€‘")
        print("-" * 60)

        response = stream_chat(prompt)

        if response:
            print(f"\nâœ… å®Œæˆï¼ç”Ÿæˆäº† {len(response)} ä¸ªå­—ç¬¦")

        print()

    print("=" * 60)
    print("æ¼”ç¤ºç»“æŸ")
    print("=" * 60)


if __name__ == "__main__":
    main()
