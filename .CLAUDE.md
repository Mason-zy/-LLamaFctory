**[AI 助手指导方案 - 项目背景、学习路径与任务计划]**
每次问你需要执行相关命令的时候需要你给出命令而不是执行也不要试图获取本机所有的信息，因为所有的代码执行都是在服务器。命令需要更新到自己的 步骤文件保证所有可以复现 然后实时更新。

- 查询官方文档必须使用：context7 MCP工具（优先级最高，查不到再使用其他mcp）
- 阅读链接必须使用：tavily - tavily-search (MCP)，严禁使用 fetch工具、Web Search工具，如果失败使用另一个web-reader、web-search-prime

必须在每个模块的Plan.md文件记录执行日志  确保整个流程可以复现，具体格式参考：C:\Users\wangy\Desktop\temp\-LLamaFctory\modules\03_vllm\PLAN.md 前223行

**代码、文档、提交信息的作者是：zhouzhiyong(需要文件头注明)，禁止出现 claude 关键字**

## 工作规范

- 多个方案时，选择最合适的方式执行，其他方案文字描述即可
- 条件不足或方案不合理时，必须明确指出并推荐更好的方案
- 每个对话完成后更新 `doc/tools/今日任务.txt`（在文件头增补，50字以内）

### 文档编写规范

**模块文档结构**：
```
modules/XX_模块名/
├── readme.md      # 教程文档（参考 03_vllm/readme.md 格式）
├── PLAN.md        # 执行计划（每日任务 + 命令 + 结果记录）
└── *.py           # 代码脚本
```

**readme.md 规范**（教程文档）：
- 必须包含目录索引
- 包含 6-7 个教程章节
- 原理讲解（带图示）
- API 使用示例
- 与其他工具对比
- 常见问题 FAQ（8+ 个问题）
- 参考：`modules/03_vllm/readme.md` (843 行)

**PLAN.md 规范**（执行计划）：
- 每日任务清单
- 执行命令（可复制）
- 实际结果记录
- 实验数据对比
- 执行日志格式参考：`modules/03_vllm/PLAN.md` 前 223 行
---

## 📌 项目进度快照

| 日期 | 阶段 | 状态 | 关键产出 |
|------|------|------|----------|
| **Day 1-2** | 单卡推理 + 图像编辑 | ✅ 已完成 | LLaMA-Factory CLI 推理 + Gradio WebUI |
| **Day 3-4** | vLLM 高性能推理 | ✅ 已完成 | PagedAttention + 双卡张量并行 14B 部署 |
| **Day 5-6** | Accelerate 分布式训练 | ✅ 已完成 | 数据并行 + BF16 + 梯度累积实验 |
| **Day 7-8** | DeepSpeed 显存优化 | ⏳ 待开始 | ZeRO 三阶段 + CPU Offload |
| **Day 9-14** | 综合实践 | ⏳ 待开始 | LLaMA-Factory 微调流程 |



---

## 一、项目目的与环境快照

### 核心目标
按"先冒烟后放大"路径，系统学习大模型推理与微调全流程：**vLLM → Accelerate → DeepSpeed → LLaMA-Factory**

### 环境快照
| 项目 | 配置 |
|------|------|
| **硬件** | 2× RTX 4090 (24GB×2 = 48GB 总显存) |
| **GPU** | CUDA 12.1 |
| **Conda 环境** | videofen |
| **PyTorch** | 2.3.1 |
| **工作目录** | `C:\Users\wangy\Desktop\temp\-LLamaFctory` |

### 资源使用约束
- **GPU 选择**：优先使用当前空闲卡（运行前先 `nvidia-smi`）
  - 单卡：`CUDA_VISIBLE_DEVICES=6`
  - 双卡：`CUDA_VISIBLE_DEVICES=6,7`
  - 如命令中有 `--gpus`：它是"可见 GPU 索引"（从 0 开始），非物理卡号
- **显存预算**：
  - 7B 全精度：约 14GB/卡
  - 14B 量化：约 10GB/卡
  - 32B 双卡：约 22GB/卡

---

## 二、前两天完成情况（✅ 已完成）

### Day 1: 单卡推理冒烟
**对应模块**：`modules/01_single_gpu_smoke/`

**完成任务**：
- [x] 环境配置（HF 镜像、缓存目录）
- [x] LLaMA-Factory CLI 安装（0.9.3 版本）
- [x] 文本模型推理（Qwen2.5-7B-Instruct）
- [x] 多模态推理（Qwen2-VL-7B-Instruct）
- [x] Web UI 体验（可选）

**验证标准**：
- CLI 出现 `>> User:` 提示并正常回复 ✅
- 多模态图像描述生成正常 ✅

**关键命令**：
```bash
# 文本推理
CUDA_VISIBLE_DEVICES=6 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --template qwen

# 多模态推理
CUDA_VISIBLE_DEVICES=6 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2-VL-7B-Instruct \
  --template qwen2_vl
```

---

### Day 2: 图像编辑服务部署
**对应模块**：`modules/02_qwen_image_edit_service/`

**完成任务**：
- [x] Qwen-Image-Edit-2511 模型下载
- [x] Diffusers Pipeline 验证
- [x] Gradio WebUI 部署
- [x] GPU/CPU 降级测试
- [x] 图像编辑功能验证

**验证标准**：
- Gradio 界面可访问（http://localhost:7860） ✅
- 图像编辑功能正常 ✅
- GPU OOM 时自动降级 CPU ✅

**关键文件**：
- `gradio_app.py` - Gradio WebUI 主程序
- `smoke_load.py` - 冒烟加载测试
- `TECHNICAL_DEPLOYMENT_GUIDE.md` - 完整技术指南

---

## 三、接下来 12 天学习计划（🚀 Day 3-14）

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   学习周期总览（Day 3-14，共 12 天）                       │
├─────────────────────────────────────────────────────────────────────────┤
│  第一阶段：基础模块学习（Day 3-8，6 天）                                   │
│    Day 3-4:  vLLM 高性能推理                                             │
│    Day 5-6:  Accelerate 分布式抽象                                        │
│    Day 7-8:  DeepSpeed 显存优化                                          │
├─────────────────────────────────────────────────────────────────────────┤
│  第二阶段：综合实践（Day 9-14，6 天）                                      │
│    Day 9-10:  LLaMA-Factory 集成框架                                      │
│    Day 11-12: 完整微调流程（文本 LoRA）                                   │
│    Day 13-14: 大模型实战（32B/70B）                                      │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 四、每日任务清单（Day 3-14）

### 📅 第一阶段：基础模块学习（Day 3-8）

#### Day 3-4: vLLM 高性能推理
**对应模块**：`modules/03_vllm/`

**学习目标**：理解 PagedAttention + Continuous Batching，双卡部署 14B 模型

**任务清单**：
- [ ] 阅读理论：`modules/03_vllm/readme.md`
- [ ] 安装 vLLM：`pip install vllm`
- [ ] 单卡部署 7B 模型（冒烟测试）
- [ ] 双卡张量并行部署 14B 模型
- [ ] OpenAI 兼容 API 测试
- [ ] GPU 监控工具使用（nvitop/gpustat）
- [ ] 性能对比：vLLM vs HuggingFace

**验证标准**：
- `nvidia-smi` 显存利用率 > 90%
- API 请求延迟 < 1s
- 双卡吞吐约单卡 1.8×

**预计时间**：2 天

---

#### Day 5-6: Accelerate 分布式抽象
**对应模块**：`modules/04_Accelerate/`

**学习目标**：掌握 Accelerator API，单代码适配多种硬件

**任务清单**：
- [ ] 阅读理论：`modules/04_Accelerate/readme.md`
- [ ] 运行配置向导：`accelerate config`
- [ ] 单卡数据并行训练冒烟
- [ ] 双卡数据并行训练
- [ ] 混合精度训练（BF16）
- [ ] 梯度累积实验

**验证标准**：
- 双卡加速比 > 1.8×
- 无 OOM 错误
- 混合精度速度提升 > 2×

**预计时间**：2 天

---

#### Day 7-8: DeepSpeed 显存优化
**对应模块**：`modules/05_DeepSpeed/`

**学习目标**：理解 ZeRO 三阶段，配置 ds_config.json

**任务清单**：
- [ ] 阅读理论：`modules/05_DeepSpeed/readme.md`
- [ ] ZeRO-1 vs ZeRO-2 vs ZeRO-3 对比实验
- [ ] CPU Offload 配置测试
- [ ] 与 Accelerate 集成启动
- [ ] 显存占用基准测试

**验证标准**：
- ZeRO-2 相比原生 DDP 显存节省 > 4×
- 训练速度下降 < 20%
- CPU Offload 成功降低显存峰值

**预计时间**：2 天

---

### 📅 第二阶段：综合实践（Day 9-14）

#### Day 9-10: LLaMA-Factory 集成框架
**学习目标**：掌握统一配置格式，切换推理/训练后端

**任务清单**：
- [ ] 阅读 `README.md` 中 LLaMA-Factory 部分
- [ ] CLI 推理测试（单卡 7B）
- [ ] Web UI 启动与功能探索
- [ ] YAML 配置文件编写
- [ ] 推理后端切换（HF/vLLM）

**验证标准**：
- CLI 推理正常响应
- Web UI 可切换模型/模板
- vLLM 后端成功部署

**预计时间**：2 天

---

#### Day 11-12: 完整微调流程（文本 LoRA）
**学习目标**：端到端跑通 LoRA 微调 + 推理验证

**任务清单**：
- [ ] 准备数据集（Alpaca-ZH 抽样 1k）
- [ ] DeepSpeed ZeRO-2 + LoRA 配置
- [ ] 双卡训练启动
- [ ] 模型评估（生成质量对比）
- [ ] 推理加载 adapter 验证

**验证标准**：
- 训练 Loss 下降正常
- 生成回复质量提升
- Adapter 加载成功

**预计时间**：2 天

---

#### Day 13-14: 大模型实战（32B/70B）
**学习目标**：双卡部署更大模型，性能基准测试

**任务清单**：
- [ ] Qwen2.5-32B 双卡推理（张量并行）
- [ ] BF16-LoRA 微调（双卡峰值 22GB/卡）
- [ ] Llama-3.1-70B NF4-QLoRA（如资源允许）
- [ ] 记录基准指标：显存峰值、训练速度、MT-bench 得分

**验证标准**：
- 显存峰值在预算内
- 训练速度 > 100 tokens/s
- 双卡加速比 > 1.8×

**预计时间**：2 天

---

## 五、通用验证与节奏

### 冒烟测试原则
```
每步先跑最小规模 → 确认无 OOM/加载错误 → 放大规模
```

### 通用测试流程
1. **单卡文本推理** → 出现 ">> User:" 并正常回复
2. **单卡多模态推理** → 图片描述生成正常
3. **多卡并行推理** → 显存约 4GB/卡，吞吐约单卡 2.3×
4. **LoRA 微调** → Loss 下降，推理验证质量提升

### 新模型/新数据验证流程
```
单卡文本 → 单卡多模态 → 多卡并行 → 上强度
```

### 异常处理
- **OOM**：优先减小 `per_device_train_batch_size` 或 `max_length`
- **加载错误**：检查模型路径、模板名称
- **训练不收敛**：检查学习率、数据格式

---

## 六、提醒事项

### 日志与监控
- 保持训练日志，关注显存与吞吐
- 使用 `nvitop` 实时监控 GPU
- 记录每次实验的配置与结果

### 资源申请
- 若需更多 GPU，请先确认资源占用
- 遵守集群使用规范

### 文档参考
| 文件 | 用途 |
|------|------|
| `README.md` | 项目总览与原理速查 |
| `.CLAUDE.md` | 本文件（AI 助手指导方案） |
| `modules/*/readme.md` | 各模块详细教程 |
| `modules/*/PLAN.md` | 具体任务清单 |

---

## 七、快速命令参考

### 单卡推理冒烟（Day 1 已验证）
```bash
CUDA_VISIBLE_DEVICES=6 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --template qwen
```

### Gradio 图像编辑服务（Day 2 已验证）
```bash
export QWEN_EDIT_2511_DIR=/path/to/Qwen-Image-Edit-2511
export CUDA_VISIBLE_DEVICES=6
python modules/02_qwen_image_edit_service/gradio_app.py
```

### vLLM 双卡推理（Day 3-4 已验证）
```bash
CUDA_VISIBLE_DEVICES=6,7 python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-14B-Instruct \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.9 \
  --port 8000
```

### 双卡 LoRA 微调（Day 11 任务）
```bash
CUDA_VISIBLE_DEVICES=6,7 deepspeed --num_gpus 2 src/train.py \
  --deepspeed examples/deepspeed/ds_z2_bf16.json \
  --stage sft \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --dataset alpaca_zh \
  --template qwen \
  --finetuning_type lora
```

### GPU 监控
```bash
# 基础监控
watch -n 1 nvidia-smi

# 交互式 TUI
pip install nvitop && nvitop

# 简洁输出
pip install gpustat && gpustat -i 1
```

---

## 八、学习路线图

```
第一阶段：冒烟测试（已完成）
├── Day 1-2: 单卡推理 + 图像编辑 ✅
│   ├── modules/01_single_gpu_smoke/
│   └── modules/02_qwen_image_edit_service/

第二阶段：基础模块学习（进行中）
├── Day 3-4: vLLM 高性能推理 ✅
│   └── modules/03_vllm/
├── Day 5-6: Accelerate 分布式训练 ✅
│   └── modules/04_Accelerate/
└── Day 7-8: DeepSpeed 优化 🚀 ← 下一个
    └── modules/05_DeepSpeed/

第三阶段：综合实践（待开始）
├── Day 9-10: LLaMA-Factory 集成
│   └── README.md + examples/
├── Day 11-12: LoRA 微调实践
│   └── examples/train_lora/
└── Day 13-14: 大模型实战
    └── 32B/70B 基准测试
```

---

**版本**: v2.2.0
**更新日期**: 2026-01-13
**当前状态**: Day 6 已完成
**下一任务**: Day 7-8 DeepSpeed 显存优化（ZeRO 三阶段 + CPU Offload）
