**[AI åŠ©æ‰‹æŒ‡å¯¼æ–¹æ¡ˆ - é¡¹ç›®èƒŒæ™¯ã€å­¦ä¹ è·¯å¾„ä¸ä»»åŠ¡è®¡åˆ’]**
æ¯æ¬¡é—®ä½ éœ€è¦æ‰§è¡Œç›¸å…³å‘½ä»¤çš„æ—¶å€™éœ€è¦ä½ ç»™å‡ºå‘½ä»¤è€Œä¸æ˜¯æ‰§è¡Œä¹Ÿä¸è¦è¯•å›¾è·å–æœ¬æœºæ‰€æœ‰çš„ä¿¡æ¯ï¼Œå› ä¸ºæ‰€æœ‰çš„ä»£ç æ‰§è¡Œéƒ½æ˜¯åœ¨æœåŠ¡å™¨ã€‚å‘½ä»¤éœ€è¦æ›´æ–°åˆ°è‡ªå·±çš„ æ­¥éª¤æ–‡ä»¶ä¿è¯æ‰€æœ‰å¯ä»¥å¤ç° ç„¶åå®æ—¶æ›´æ–°ã€‚
---

## ğŸ“Œ é¡¹ç›®è¿›åº¦å¿«ç…§

| æ—¥æœŸ | é˜¶æ®µ | çŠ¶æ€ | å…³é”®äº§å‡º |
|------|------|------|----------|
| **Day 1** | å•å¡æ¨ç†å†’çƒŸ | âœ… å·²å®Œæˆ | LLaMA-Factory CLI æ–‡æœ¬/å¤šæ¨¡æ€æ¨ç†éªŒè¯ |
| **Day 2** | å›¾åƒç¼–è¾‘æœåŠ¡ | âœ… å·²å®Œæˆ | Qwen-Image-Edit-2511 Gradio WebUI éƒ¨ç½² |
| **Day 3-8** | åŸºç¡€æ¨¡å—å­¦ä¹  | ğŸš€ è¿›è¡Œä¸­ | vLLM â†’ Accelerate â†’ DeepSpeed |
| **Day 9-14** | ç»¼åˆå®è·µ | â³ å¾…å¼€å§‹ | LLaMA-Factory å¾®è°ƒæµç¨‹ |

**å½“å‰ä½ç½®**ï¼šDay 3ï¼Œå¼€å§‹ vLLM é«˜æ€§èƒ½æ¨ç†æ¨¡å—

---

## ä¸€ã€é¡¹ç›®ç›®çš„ä¸ç¯å¢ƒå¿«ç…§

### æ ¸å¿ƒç›®æ ‡
æŒ‰"å…ˆå†’çƒŸåæ”¾å¤§"è·¯å¾„ï¼Œç³»ç»Ÿå­¦ä¹ å¤§æ¨¡å‹æ¨ç†ä¸å¾®è°ƒå…¨æµç¨‹ï¼š**vLLM â†’ Accelerate â†’ DeepSpeed â†’ LLaMA-Factory**

### ç¯å¢ƒå¿«ç…§
| é¡¹ç›® | é…ç½® |
|------|------|
| **ç¡¬ä»¶** | 2Ã— RTX 4090 (24GBÃ—2 = 48GB æ€»æ˜¾å­˜) |
| **GPU** | CUDA 12.1 |
| **Conda ç¯å¢ƒ** | videofen |
| **PyTorch** | 2.3.1 |
| **å·¥ä½œç›®å½•** | `C:\Users\wangy\Desktop\temp\-LLamaFctory` |

### èµ„æºä½¿ç”¨çº¦æŸ
- **GPU é€‰æ‹©**ï¼šä¼˜å…ˆä½¿ç”¨å½“å‰ç©ºé—²å¡ï¼ˆè¿è¡Œå‰å…ˆ `nvidia-smi`ï¼‰
  - å•å¡ï¼š`CUDA_VISIBLE_DEVICES=0`
  - åŒå¡ï¼š`CUDA_VISIBLE_DEVICES=0,1`
  - å¦‚å‘½ä»¤ä¸­æœ‰ `--gpus`ï¼šå®ƒæ˜¯"å¯è§ GPU ç´¢å¼•"ï¼ˆä» 0 å¼€å§‹ï¼‰ï¼Œéç‰©ç†å¡å·
- **æ˜¾å­˜é¢„ç®—**ï¼š
  - 7B å…¨ç²¾åº¦ï¼šçº¦ 14GB/å¡
  - 14B é‡åŒ–ï¼šçº¦ 10GB/å¡
  - 32B åŒå¡ï¼šçº¦ 22GB/å¡

---

## äºŒã€å‰ä¸¤å¤©å®Œæˆæƒ…å†µï¼ˆâœ… å·²å®Œæˆï¼‰

### Day 1: å•å¡æ¨ç†å†’çƒŸ
**å¯¹åº”æ¨¡å—**ï¼š`modules/01_single_gpu_smoke/`

**å®Œæˆä»»åŠ¡**ï¼š
- [x] ç¯å¢ƒé…ç½®ï¼ˆHF é•œåƒã€ç¼“å­˜ç›®å½•ï¼‰
- [x] LLaMA-Factory CLI å®‰è£…ï¼ˆ0.9.3 ç‰ˆæœ¬ï¼‰
- [x] æ–‡æœ¬æ¨¡å‹æ¨ç†ï¼ˆQwen2.5-7B-Instructï¼‰
- [x] å¤šæ¨¡æ€æ¨ç†ï¼ˆQwen2-VL-7B-Instructï¼‰
- [x] Web UI ä½“éªŒï¼ˆå¯é€‰ï¼‰

**éªŒè¯æ ‡å‡†**ï¼š
- CLI å‡ºç° `>> User:` æç¤ºå¹¶æ­£å¸¸å›å¤ âœ…
- å¤šæ¨¡æ€å›¾åƒæè¿°ç”Ÿæˆæ­£å¸¸ âœ…

**å…³é”®å‘½ä»¤**ï¼š
```bash
# æ–‡æœ¬æ¨ç†
CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --template qwen

# å¤šæ¨¡æ€æ¨ç†
CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2-VL-7B-Instruct \
  --template qwen2_vl
```

---

### Day 2: å›¾åƒç¼–è¾‘æœåŠ¡éƒ¨ç½²
**å¯¹åº”æ¨¡å—**ï¼š`modules/02_qwen_image_edit_service/`

**å®Œæˆä»»åŠ¡**ï¼š
- [x] Qwen-Image-Edit-2511 æ¨¡å‹ä¸‹è½½
- [x] Diffusers Pipeline éªŒè¯
- [x] Gradio WebUI éƒ¨ç½²
- [x] GPU/CPU é™çº§æµ‹è¯•
- [x] å›¾åƒç¼–è¾‘åŠŸèƒ½éªŒè¯

**éªŒè¯æ ‡å‡†**ï¼š
- Gradio ç•Œé¢å¯è®¿é—®ï¼ˆhttp://localhost:7860ï¼‰ âœ…
- å›¾åƒç¼–è¾‘åŠŸèƒ½æ­£å¸¸ âœ…
- GPU OOM æ—¶è‡ªåŠ¨é™çº§ CPU âœ…

**å…³é”®æ–‡ä»¶**ï¼š
- `gradio_app.py` - Gradio WebUI ä¸»ç¨‹åº
- `smoke_load.py` - å†’çƒŸåŠ è½½æµ‹è¯•
- `TECHNICAL_DEPLOYMENT_GUIDE.md` - å®Œæ•´æŠ€æœ¯æŒ‡å—

---

## ä¸‰ã€æ¥ä¸‹æ¥ 12 å¤©å­¦ä¹ è®¡åˆ’ï¼ˆğŸš€ Day 3-14ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å­¦ä¹ å‘¨æœŸæ€»è§ˆï¼ˆDay 3-14ï¼Œå…± 12 å¤©ï¼‰                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¨¡å—å­¦ä¹ ï¼ˆDay 3-8ï¼Œ6 å¤©ï¼‰                                   â”‚
â”‚    Day 3-4:  vLLM é«˜æ€§èƒ½æ¨ç†                                             â”‚
â”‚    Day 5-6:  Accelerate åˆ†å¸ƒå¼æŠ½è±¡                                        â”‚
â”‚    Day 7-8:  DeepSpeed æ˜¾å­˜ä¼˜åŒ–                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç¬¬äºŒé˜¶æ®µï¼šç»¼åˆå®è·µï¼ˆDay 9-14ï¼Œ6 å¤©ï¼‰                                      â”‚
â”‚    Day 9-10:  LLaMA-Factory é›†æˆæ¡†æ¶                                      â”‚
â”‚    Day 11-12: å®Œæ•´å¾®è°ƒæµç¨‹ï¼ˆæ–‡æœ¬ LoRAï¼‰                                   â”‚
â”‚    Day 13-14: å¤§æ¨¡å‹å®æˆ˜ï¼ˆ32B/70Bï¼‰                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å››ã€æ¯æ—¥ä»»åŠ¡æ¸…å•ï¼ˆDay 3-14ï¼‰

### ğŸ“… ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¨¡å—å­¦ä¹ ï¼ˆDay 3-8ï¼‰

#### Day 3-4: vLLM é«˜æ€§èƒ½æ¨ç†
**å¯¹åº”æ¨¡å—**ï¼š`modules/03_vllm/`

**å­¦ä¹ ç›®æ ‡**ï¼šç†è§£ PagedAttention + Continuous Batchingï¼ŒåŒå¡éƒ¨ç½² 14B æ¨¡å‹

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] é˜…è¯»ç†è®ºï¼š`modules/03_vllm/readme.md`
- [ ] å®‰è£… vLLMï¼š`pip install vllm`
- [ ] å•å¡éƒ¨ç½² 7B æ¨¡å‹ï¼ˆå†’çƒŸæµ‹è¯•ï¼‰
- [ ] åŒå¡å¼ é‡å¹¶è¡Œéƒ¨ç½² 14B æ¨¡å‹
- [ ] OpenAI å…¼å®¹ API æµ‹è¯•
- [ ] GPU ç›‘æ§å·¥å…·ä½¿ç”¨ï¼ˆnvitop/gpustatï¼‰
- [ ] æ€§èƒ½å¯¹æ¯”ï¼švLLM vs HuggingFace

**éªŒè¯æ ‡å‡†**ï¼š
- `nvidia-smi` æ˜¾å­˜åˆ©ç”¨ç‡ > 90%
- API è¯·æ±‚å»¶è¿Ÿ < 1s
- åŒå¡ååçº¦å•å¡ 1.8Ã—

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

#### Day 5-6: Accelerate åˆ†å¸ƒå¼æŠ½è±¡
**å¯¹åº”æ¨¡å—**ï¼š`modules/04_Accelerate/`

**å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡ Accelerator APIï¼Œå•ä»£ç é€‚é…å¤šç§ç¡¬ä»¶

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] é˜…è¯»ç†è®ºï¼š`modules/04_Accelerate/readme.md`
- [ ] è¿è¡Œé…ç½®å‘å¯¼ï¼š`accelerate config`
- [ ] å•å¡æ•°æ®å¹¶è¡Œè®­ç»ƒå†’çƒŸ
- [ ] åŒå¡æ•°æ®å¹¶è¡Œè®­ç»ƒ
- [ ] æ··åˆç²¾åº¦è®­ç»ƒï¼ˆBF16ï¼‰
- [ ] æ¢¯åº¦ç´¯ç§¯å®éªŒ

**éªŒè¯æ ‡å‡†**ï¼š
- åŒå¡åŠ é€Ÿæ¯” > 1.8Ã—
- æ—  OOM é”™è¯¯
- æ··åˆç²¾åº¦é€Ÿåº¦æå‡ > 2Ã—

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

#### Day 7-8: DeepSpeed æ˜¾å­˜ä¼˜åŒ–
**å¯¹åº”æ¨¡å—**ï¼š`modules/05_DeepSpeed/`

**å­¦ä¹ ç›®æ ‡**ï¼šç†è§£ ZeRO ä¸‰é˜¶æ®µï¼Œé…ç½® ds_config.json

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] é˜…è¯»ç†è®ºï¼š`modules/05_DeepSpeed/readme.md`
- [ ] ZeRO-1 vs ZeRO-2 vs ZeRO-3 å¯¹æ¯”å®éªŒ
- [ ] CPU Offload é…ç½®æµ‹è¯•
- [ ] ä¸ Accelerate é›†æˆå¯åŠ¨
- [ ] æ˜¾å­˜å ç”¨åŸºå‡†æµ‹è¯•

**éªŒè¯æ ‡å‡†**ï¼š
- ZeRO-2 ç›¸æ¯”åŸç”Ÿ DDP æ˜¾å­˜èŠ‚çœ > 4Ã—
- è®­ç»ƒé€Ÿåº¦ä¸‹é™ < 20%
- CPU Offload æˆåŠŸé™ä½æ˜¾å­˜å³°å€¼

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

### ğŸ“… ç¬¬äºŒé˜¶æ®µï¼šç»¼åˆå®è·µï¼ˆDay 9-14ï¼‰

#### Day 9-10: LLaMA-Factory é›†æˆæ¡†æ¶
**å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡ç»Ÿä¸€é…ç½®æ ¼å¼ï¼Œåˆ‡æ¢æ¨ç†/è®­ç»ƒåç«¯

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] é˜…è¯» `README.md` ä¸­ LLaMA-Factory éƒ¨åˆ†
- [ ] CLI æ¨ç†æµ‹è¯•ï¼ˆå•å¡ 7Bï¼‰
- [ ] Web UI å¯åŠ¨ä¸åŠŸèƒ½æ¢ç´¢
- [ ] YAML é…ç½®æ–‡ä»¶ç¼–å†™
- [ ] æ¨ç†åç«¯åˆ‡æ¢ï¼ˆHF/vLLMï¼‰

**éªŒè¯æ ‡å‡†**ï¼š
- CLI æ¨ç†æ­£å¸¸å“åº”
- Web UI å¯åˆ‡æ¢æ¨¡å‹/æ¨¡æ¿
- vLLM åç«¯æˆåŠŸéƒ¨ç½²

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

#### Day 11-12: å®Œæ•´å¾®è°ƒæµç¨‹ï¼ˆæ–‡æœ¬ LoRAï¼‰
**å­¦ä¹ ç›®æ ‡**ï¼šç«¯åˆ°ç«¯è·‘é€š LoRA å¾®è°ƒ + æ¨ç†éªŒè¯

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å‡†å¤‡æ•°æ®é›†ï¼ˆAlpaca-ZH æŠ½æ · 1kï¼‰
- [ ] DeepSpeed ZeRO-2 + LoRA é…ç½®
- [ ] åŒå¡è®­ç»ƒå¯åŠ¨
- [ ] æ¨¡å‹è¯„ä¼°ï¼ˆç”Ÿæˆè´¨é‡å¯¹æ¯”ï¼‰
- [ ] æ¨ç†åŠ è½½ adapter éªŒè¯

**éªŒè¯æ ‡å‡†**ï¼š
- è®­ç»ƒ Loss ä¸‹é™æ­£å¸¸
- ç”Ÿæˆå›å¤è´¨é‡æå‡
- Adapter åŠ è½½æˆåŠŸ

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

#### Day 13-14: å¤§æ¨¡å‹å®æˆ˜ï¼ˆ32B/70Bï¼‰
**å­¦ä¹ ç›®æ ‡**ï¼šåŒå¡éƒ¨ç½²æ›´å¤§æ¨¡å‹ï¼Œæ€§èƒ½åŸºå‡†æµ‹è¯•

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] Qwen2.5-32B åŒå¡æ¨ç†ï¼ˆå¼ é‡å¹¶è¡Œï¼‰
- [ ] BF16-LoRA å¾®è°ƒï¼ˆåŒå¡å³°å€¼ 22GB/å¡ï¼‰
- [ ] Llama-3.1-70B NF4-QLoRAï¼ˆå¦‚èµ„æºå…è®¸ï¼‰
- [ ] è®°å½•åŸºå‡†æŒ‡æ ‡ï¼šæ˜¾å­˜å³°å€¼ã€è®­ç»ƒé€Ÿåº¦ã€MT-bench å¾—åˆ†

**éªŒè¯æ ‡å‡†**ï¼š
- æ˜¾å­˜å³°å€¼åœ¨é¢„ç®—å†…
- è®­ç»ƒé€Ÿåº¦ > 100 tokens/s
- åŒå¡åŠ é€Ÿæ¯” > 1.8Ã—

**é¢„è®¡æ—¶é—´**ï¼š2 å¤©

---

## äº”ã€é€šç”¨éªŒè¯ä¸èŠ‚å¥

### å†’çƒŸæµ‹è¯•åŸåˆ™
```
æ¯æ­¥å…ˆè·‘æœ€å°è§„æ¨¡ â†’ ç¡®è®¤æ—  OOM/åŠ è½½é”™è¯¯ â†’ æ”¾å¤§è§„æ¨¡
```

### é€šç”¨æµ‹è¯•æµç¨‹
1. **å•å¡æ–‡æœ¬æ¨ç†** â†’ å‡ºç° ">> User:" å¹¶æ­£å¸¸å›å¤
2. **å•å¡å¤šæ¨¡æ€æ¨ç†** â†’ å›¾ç‰‡æè¿°ç”Ÿæˆæ­£å¸¸
3. **å¤šå¡å¹¶è¡Œæ¨ç†** â†’ æ˜¾å­˜çº¦ 4GB/å¡ï¼Œååçº¦å•å¡ 2.3Ã—
4. **LoRA å¾®è°ƒ** â†’ Loss ä¸‹é™ï¼Œæ¨ç†éªŒè¯è´¨é‡æå‡

### æ–°æ¨¡å‹/æ–°æ•°æ®éªŒè¯æµç¨‹
```
å•å¡æ–‡æœ¬ â†’ å•å¡å¤šæ¨¡æ€ â†’ å¤šå¡å¹¶è¡Œ â†’ ä¸Šå¼ºåº¦
```

### å¼‚å¸¸å¤„ç†
- **OOM**ï¼šä¼˜å…ˆå‡å° `per_device_train_batch_size` æˆ– `max_length`
- **åŠ è½½é”™è¯¯**ï¼šæ£€æŸ¥æ¨¡å‹è·¯å¾„ã€æ¨¡æ¿åç§°
- **è®­ç»ƒä¸æ”¶æ•›**ï¼šæ£€æŸ¥å­¦ä¹ ç‡ã€æ•°æ®æ ¼å¼

---

## å…­ã€æé†’äº‹é¡¹

### æ—¥å¿—ä¸ç›‘æ§
- ä¿æŒè®­ç»ƒæ—¥å¿—ï¼Œå…³æ³¨æ˜¾å­˜ä¸åå
- ä½¿ç”¨ `nvitop` å®æ—¶ç›‘æ§ GPU
- è®°å½•æ¯æ¬¡å®éªŒçš„é…ç½®ä¸ç»“æœ

### èµ„æºç”³è¯·
- è‹¥éœ€æ›´å¤š GPUï¼Œè¯·å…ˆç¡®è®¤èµ„æºå ç”¨
- éµå®ˆé›†ç¾¤ä½¿ç”¨è§„èŒƒ

### æ–‡æ¡£å‚è€ƒ
| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `README.md` | é¡¹ç›®æ€»è§ˆä¸åŸç†é€ŸæŸ¥ |
| `.CLAUDE.md` | æœ¬æ–‡ä»¶ï¼ˆAI åŠ©æ‰‹æŒ‡å¯¼æ–¹æ¡ˆï¼‰ |
| `modules/*/readme.md` | å„æ¨¡å—è¯¦ç»†æ•™ç¨‹ |
| `modules/*/PLAN.md` | å…·ä½“ä»»åŠ¡æ¸…å• |

---

## ä¸ƒã€å¿«é€Ÿå‘½ä»¤å‚è€ƒ

### å•å¡æ¨ç†å†’çƒŸï¼ˆDay 1 å·²éªŒè¯ï¼‰
```bash
CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --template qwen
```

### Gradio å›¾åƒç¼–è¾‘æœåŠ¡ï¼ˆDay 2 å·²éªŒè¯ï¼‰
```bash
export QWEN_EDIT_2511_DIR=/path/to/Qwen-Image-Edit-2511
export CUDA_VISIBLE_DEVICES=0
python modules/02_qwen_image_edit_service/gradio_app.py
```

### vLLM åŒå¡æ¨ç†ï¼ˆDay 3 ä»»åŠ¡ï¼‰
```bash
CUDA_VISIBLE_DEVICES=0,1 python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-14B-Instruct \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.9 \
  --port 8000
```

### åŒå¡ LoRA å¾®è°ƒï¼ˆDay 11 ä»»åŠ¡ï¼‰
```bash
CUDA_VISIBLE_DEVICES=0,1 deepspeed --num_gpus 2 src/train.py \
  --deepspeed examples/deepspeed/ds_z2_bf16.json \
  --stage sft \
  --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
  --dataset alpaca_zh \
  --template qwen \
  --finetuning_type lora
```

### GPU ç›‘æ§
```bash
# åŸºç¡€ç›‘æ§
watch -n 1 nvidia-smi

# äº¤äº’å¼ TUI
pip install nvitop && nvitop

# ç®€æ´è¾“å‡º
pip install gpustat && gpustat -i 1
```

---

## å…«ã€å­¦ä¹ è·¯çº¿å›¾

```
å‰ä¸¤å¤©ï¼ˆå·²å®Œæˆï¼‰
â”œâ”€â”€ Day 1: å•å¡æ¨ç†å†’çƒŸ âœ…
â”‚   â””â”€â”€ modules/01_single_gpu_smoke/
â””â”€â”€ Day 2: å›¾åƒç¼–è¾‘æœåŠ¡ âœ…
    â””â”€â”€ modules/02_qwen_image_edit_service/

æ¥ä¸‹æ¥ 12 å¤©ï¼ˆDay 3-14ï¼‰
â”œâ”€â”€ Day 3-4: vLLM æ¨ç† ğŸš€
â”‚   â””â”€â”€ modules/03_vllm/
â”œâ”€â”€ Day 5-6: Accelerate åˆ†å¸ƒå¼
â”‚   â””â”€â”€ modules/04_Accelerate/
â”œâ”€â”€ Day 7-8: DeepSpeed ä¼˜åŒ–
â”‚   â””â”€â”€ modules/05_DeepSpeed/
â”œâ”€â”€ Day 9-10: LLaMA-Factory é›†æˆ
â”‚   â””â”€â”€ README.md + examples/
â”œâ”€â”€ Day 11-12: LoRA å¾®è°ƒå®è·µ
â”‚   â””â”€â”€ examples/train_lora/
â””â”€â”€ Day 13-14: å¤§æ¨¡å‹å®æˆ˜
    â””â”€â”€ 32B/70B åŸºå‡†æµ‹è¯•
```

---

**ç‰ˆæœ¬**: v2.0.0
**æ›´æ–°æ—¥æœŸ**: 2026-01-09
**å½“å‰çŠ¶æ€**: Day 3 è¿›è¡Œä¸­
**ä¸‹ä¸€ä»»åŠ¡**: vLLM é«˜æ€§èƒ½æ¨ç†æ¨¡å—
